{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4noH7q4USKQ"
   },
   "source": [
    "# Feature Engineering and Modelling\n",
    "\n",
    "---\n",
    "\n",
    "1. Import packages\n",
    "2. Load data\n",
    "3. Modelling\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NwE6osQpUSKS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cm3WmjAZUSKT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Shows plots in jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plot style\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sewogUFaUSKU"
   },
   "source": [
    "---\n",
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oaIJfXJjUSKU",
    "outputId": "c218e74d-f4bb-4150-b1e3-22d38d83fc07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>forecast_discount_energy</th>\n",
       "      <th>forecast_meter_rent_12m</th>\n",
       "      <th>forecast_price_energy_off_peak</th>\n",
       "      <th>forecast_price_energy_peak</th>\n",
       "      <th>forecast_price_pow_off_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>months_modif_prod</th>\n",
       "      <th>months_renewal</th>\n",
       "      <th>channel_MISSING</th>\n",
       "      <th>channel_ewpakwlliwisiwduibdlfmalxowmwpci</th>\n",
       "      <th>channel_foosdfpfkusacimwkcsosbicdxkicaua</th>\n",
       "      <th>channel_lmkebamcaaclubfxadlmueccxoimlema</th>\n",
       "      <th>channel_usilxuppasemubllopkaafesmlibmsdf</th>\n",
       "      <th>origin_up_kamkkxfxxuwbdslkwifmmcsiusiuosws</th>\n",
       "      <th>origin_up_ldkssxwpmemidmecebumciepifcamkci</th>\n",
       "      <th>origin_up_lxidpiddsbxsbosboudacockeimpuepw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24011ae4ebbe3035111d65fa7c15bc57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.739944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444045</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d29c2c54acc38ff3c0614d0a653813dd</td>\n",
       "      <td>3.668479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.280920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.237292</td>\n",
       "      <td>0.145711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>764c75f661154dac3a6c254cd082ea7d</td>\n",
       "      <td>2.736397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.689841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599009</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bba03439a292a1e166f80264c16191cb</td>\n",
       "      <td>3.200029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.382089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318689</td>\n",
       "      <td>0.146694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149d57cf92fc41cf94415803a877cb4b</td>\n",
       "      <td>3.646011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.721811</td>\n",
       "      <td>2.650065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.122969</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  cons_12m  cons_gas_12m  cons_last_month  \\\n",
       "0  24011ae4ebbe3035111d65fa7c15bc57  0.000000      4.739944         0.000000   \n",
       "1  d29c2c54acc38ff3c0614d0a653813dd  3.668479      0.000000         0.000000   \n",
       "2  764c75f661154dac3a6c254cd082ea7d  2.736397      0.000000         0.000000   \n",
       "3  bba03439a292a1e166f80264c16191cb  3.200029      0.000000         0.000000   \n",
       "4  149d57cf92fc41cf94415803a877cb4b  3.646011      0.000000         2.721811   \n",
       "\n",
       "   forecast_cons_12m  forecast_discount_energy  forecast_meter_rent_12m  \\\n",
       "0           0.000000                       0.0                 0.444045   \n",
       "1           2.280920                       0.0                 1.237292   \n",
       "2           1.689841                       0.0                 1.599009   \n",
       "3           2.382089                       0.0                 1.318689   \n",
       "4           2.650065                       0.0                 2.122969   \n",
       "\n",
       "   forecast_price_energy_off_peak  forecast_price_energy_peak  \\\n",
       "0                        0.114481                    0.098142   \n",
       "1                        0.145711                    0.000000   \n",
       "2                        0.165794                    0.087899   \n",
       "3                        0.146694                    0.000000   \n",
       "4                        0.116900                    0.100015   \n",
       "\n",
       "   forecast_price_pow_off_peak  ...  months_modif_prod  months_renewal  \\\n",
       "0                    40.606701  ...                  2               6   \n",
       "1                    44.311378  ...                 76               4   \n",
       "2                    44.311378  ...                 68               8   \n",
       "3                    44.311378  ...                 69               9   \n",
       "4                    40.606701  ...                 71               9   \n",
       "\n",
       "   channel_MISSING  channel_ewpakwlliwisiwduibdlfmalxowmwpci  \\\n",
       "0                0                                         0   \n",
       "1                1                                         0   \n",
       "2                0                                         0   \n",
       "3                0                                         0   \n",
       "4                1                                         0   \n",
       "\n",
       "   channel_foosdfpfkusacimwkcsosbicdxkicaua  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   channel_lmkebamcaaclubfxadlmueccxoimlema  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   channel_usilxuppasemubllopkaafesmlibmsdf  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   origin_up_kamkkxfxxuwbdslkwifmmcsiusiuosws  \\\n",
       "0                                           0   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "   origin_up_ldkssxwpmemidmecebumciepifcamkci  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   origin_up_lxidpiddsbxsbosboudacockeimpuepw  \n",
       "0                                           1  \n",
       "1                                           0  \n",
       "2                                           0  \n",
       "3                                           0  \n",
       "4                                           0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data_for_predictions.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2gjvbtCUSKV"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Modelling\n",
    "\n",
    "We now have a dataset containing features that we have engineered and we are ready to start training a predictive model. Remember, we only need to focus on training a `Random Forest` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cPHZWHC8USKV"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PitUvSFhUSKV"
   },
   "source": [
    "### Data sampling\n",
    "\n",
    "The first thing we want to do is split our dataset into training and test samples. The reason why we do this, is so that we can simulate a real life situation by generating predictions for our test sample, without showing the predictive model these data points. This gives us the ability to see how well our model is able to generalise to new data, which is critical.\n",
    "\n",
    "A typical % to dedicate to testing is between 20-30, for this example we will use a 75-25% split between train and test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dstIVhBnUSKW",
    "outputId": "fdc82a65-36c0-4229-d729-161989dccda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14606, 61)\n",
      "(14606,)\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of our data\n",
    "train_df = df.copy()\n",
    "\n",
    "# Separate target variable from independent variables\n",
    "y = df['churn']\n",
    "X = df.drop(columns=['id', 'churn'])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ifim4p1WUSKW",
    "outputId": "d689475d-555c-48d0-a0be-a0fbe812ab47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10954, 61)\n",
      "(10954,)\n",
      "(3652, 61)\n",
      "(3652,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22A_oe_PUSKX"
   },
   "source": [
    "### Model training\n",
    "\n",
    "Once again, we are using a `Random Forest` classifier in this example. A Random Forest sits within the category of `ensemble` algorithms because internally the `Forest` refers to a collection of `Decision Trees` which are tree-based learning algorithms. As the data scientist, you can control how large the forest is (that is, how many decision trees you want to include).\n",
    "\n",
    "The reason why an `ensemble` algorithm is powerful is because of the laws of averaging, weak learners and the central limit theorem. If we take a single decision tree and give it a sample of data and some parameters, it will learn patterns from the data. It may be overfit or it may be underfit, but that is now our only hope, that single algorithm. \n",
    "\n",
    "With `ensemble` methods, instead of banking on 1 single trained model, we can train 1000's of decision trees, all using different splits of the data and learning different patterns. It would be like asking 1000 people to all learn how to code. You would end up with 1000 people with different answers, methods and styles! The weak learner notion applies here too, it has been found that if you train your learners not to overfit, but to learn weak patterns within the data and you have a lot of these weak learners, together they come together to form a highly predictive pool of knowledge! This is a real life application of many brains are better than 1.\n",
    "\n",
    "Now instead of relying on 1 single decision tree for prediction, the random forest puts it to the overall views of the entire collection of decision trees. Some ensemble algorithms using a voting approach to decide which prediction is best, others using averaging. \n",
    "\n",
    "As we increase the number of learners, the idea is that the random forest's performance should converge to its best possible solution.\n",
    "\n",
    "Some additional advantages of the random forest classifier include:\n",
    "\n",
    "- The random forest uses a rule-based approach instead of a distance calculation and so features do not need to be scaled\n",
    "- It is able to handle non-linear parameters better than linear based models\n",
    "\n",
    "On the flip side, some disadvantages of the random forest classifier include:\n",
    "\n",
    "- The computational power needed to train a random forest on a large dataset is high, since we need to build a whole ensemble of estimators.\n",
    "- Training time can be longer due to the increased complexity and size of thee ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "km_R7pYnUSKX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, min_samples_split=10,\n",
       "                       n_estimators=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, min_samples_split=10,\n",
       "                       n_estimators=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', min_samples_split=10,\n",
       "                       n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier with the following hyperparameters:\n",
    "# n_estimators: Number of trees in the forest. Setting to 1000 for a more robust model.\n",
    "# criterion: 'entropy' specifies that the model will use the information gain for splitting the nodes.\n",
    "# min_samples_split: Minimum number of samples required to split an internal node. Setting this to 10 helps prevent overfitting.\n",
    "# random_state: Setting a random seed to 42 for reproducibility so that you get the same results every time you run the model.\n",
    "rf = RandomForestClassifier(n_estimators=1000, criterion='entropy', min_samples_split=10, random_state=42)\n",
    "\n",
    "# Train (fit) the RandomForestClassifier on the training data.\n",
    "# X_train: Features of the training dataset.\n",
    "# y_train: Target variable of the training dataset.\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# After this, the model has been trained on the training data and is ready to make predictions or be evaluated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the RandomForestClassifier on the test set.\n",
    "# X_test: The features of the test set that the model hasn't seen during training.\n",
    "# The model will predict the target labels for these test data points.\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf #contains the predicted class labels for your test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 12\n",
      "False positives: 1\n",
      "True negatives: 3285\n",
      "False negatives: 354\n",
      "\n",
      "Accuracy: 0.9027929901423878\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.03278688524590164\n"
     ]
    }
   ],
   "source": [
    "print(f\"True positives: {tp}\")\n",
    "print(f\"False positives: {fp}\")\n",
    "print(f\"False negatives: {fn}\\n\")\n",
    "\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, predictions)}\")\n",
    "print(f\"Precision: {metrics.precision_score(y_test, predictions)}\")\n",
    "print(f\"Recall: {metrics.recall_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwueFNNZUSKY"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Now let's evaluate how well this trained model is able to predict the values of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027929901423878"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance of the RandomForestClassifier on the test set.\n",
    "# The score method computes the mean accuracy of the model's predictions.\n",
    "# X_test: The features of the test set.\n",
    "# y_test: The true labels of the test set.\n",
    "# The method returns the accuracy, which is the proportion of correctly predicted samples.\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy on the test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ncDbDAcJUSKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9027929901423878\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.03278688524590164\n",
      "F1-Score: 0.0633245382585752\n",
      "ROC-AUC Score: 0.516241281941271\n",
      "Confusion Matrix:\n",
      "[[3285    1]\n",
      " [ 354   12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Calculate accuracy: the proportion of correctly predicted samples.\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate precision: the proportion of true positives among the predicted positives.\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate recall: the proportion of true positives among the actual positives.\n",
    "recall = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate F1-Score: the harmonic mean of precision and recall.\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate ROC-AUC Score: the area under the ROC curve, which measures the trade-off between true positive rate and false positive rate.\n",
    "roc_auc = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "# Calculate the confusion matrix: a table showing the counts of true positives, false positives, true negatives, and false negatives.\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      3286\n",
      "           1       0.92      0.03      0.06       366\n",
      "\n",
      "    accuracy                           0.90      3652\n",
      "   macro avg       0.91      0.52      0.51      3652\n",
      "weighted avg       0.90      0.90      0.86      3652\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate and print the classification report for the test data.\n",
    "# y_test: True labels for the test set.\n",
    "# y_pred_rf: Predicted labels by the RandomForestClassifier for the test set.\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance Summary\n",
    "\n",
    "Accuracy: 0.9028\n",
    "The model correctly predicted whether customers would churn or not about 90.28% of the time. While this figure seems high, in the context of churn prediction, it may be misleading due to potential class imbalance.\n",
    "\n",
    "Precision: 0.9231\n",
    "When the model predicts a customer will churn, it is correct about 92.31% of the time. This high precision indicates that the model is accurate when it does identify churners.\n",
    "\n",
    "Recall: 0.0328\n",
    "The model identified only 3.28% of the actual churners. This is extremely low, showing that the model is missing most of the churners, which is a critical issue since the primary goal is to detect as many churners as possible.\n",
    "\n",
    "F1-Score: 0.0633\n",
    "The F1-Score, which balances precision and recall, is very low. This reflects the poor performance in terms of recall, despite high precision.\n",
    "\n",
    "ROC-AUC Score: 0.5162\n",
    "The ROC-AUC score is just slightly above 0.5, indicating that the model performs nearly as well as random guessing in distinguishing between churners and non-churners.\n",
    "\n",
    "Confusion Matrix:\n",
    "[[3285    1]\n",
    " [ 354   12]]\n",
    "The confusion matrix shows that the model correctly predicted 3285 non-churners (true negatives) and 12 churners (true positives). However, it incorrectly predicted 354 actual churners as non-churners (false negatives) and only 1 non-churner as a churner (false positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the Modelâ€™s Performance Satisfactory for me?\n",
    "\n",
    "The modelâ€™s performance is not satisfactory. Despite the high accuracy and precision, \n",
    "the model fails to identify most of the actual churners, which is the primary objective of the churn prediction task. \n",
    "The very low recall and F1-Score, along with a ROC-AUC score close to random guessing, suggest that the model is not \n",
    "effectively distinguishing between churners and non-churners."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "152bf6e7dc8ee53edb5af21dc1a8faeab7f134840808a94079ed98d91ece7e0c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
